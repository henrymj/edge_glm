{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71896f8d-4cc2-4064-9469-3330d68d24a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/accel/lib/python3.10/site-packages/nilearn/glm/__init__.py:55: FutureWarning: The nilearn.glm module is experimental. It may change in any future release of Nilearn.\n",
      "  warn('The nilearn.glm module is experimental. '\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import path\n",
    "from collections import defaultdict\n",
    "from scipy.io import loadmat\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "\n",
    "# imports for data loading, processing and analysis\n",
    "from utils.io import get_args, get_firstlevel_dir, save_args, load_data\n",
    "from utils.preprocessing import set_get_timeseries, build_sub_run_df, convert_df_to_desMat, add_VTC_get_breaks, exclude_irrelevant_VTC_TRs, check_dataset2_censored_trs\n",
    "from utils.nilearn_analysis import get_contrast_info, fit_edge_flm, get_flm_attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1702b514-7702-4c59-ae47-ea462bc9791a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set rng for replication\n",
    "np.random.seed(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e28d47d0-3029-4f53-854a-2a02690dd578",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = get_args(['-dataset', '2'])\n",
    "args.model = 'VTC_shifted' # hard coding to make sure VTC shift and break clipping occurs\n",
    "\n",
    "# Set up directories, load data\n",
    "results_dir = get_firstlevel_dir(args)\n",
    "save_args(args, results_dir)\n",
    "\n",
    "ridx, cidx = np.tril_indices(args.nROI, -1)\n",
    "get_timeseries = set_get_timeseries(args, ridx, cidx)  # set the type of timeseries to use, ROI or edge\n",
    "\n",
    "contrasts, contrast_cols = get_contrast_info(args)\n",
    "\n",
    "timeseries_data, sub_file_map, sublist, ntr_tossed = load_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95625768-33a1-4d04-af52-bbd9eeffd692",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n",
      "A 'modulation' column was found in the given events data and is used.\n"
     ]
    }
   ],
   "source": [
    "# PREPROCESS BEHAV DATA, MAKE DESIGN MATRICES\n",
    "des_mat_dict = defaultdict(list)\n",
    "fitable_timeseries = defaultdict(list)\n",
    "for sidx, sub in enumerate(sublist):\n",
    "    sub_files = sub_file_map[sidx]\n",
    "\n",
    "    for runidx, sub_file in enumerate(sub_files):\n",
    "        sub_trs = np.arange(timeseries_data[sidx][runidx].shape[0])*args.t_r\n",
    "        \n",
    "        sub_run_df = build_sub_run_df(loadmat(sub_file), ntr_tossed, args)\n",
    "        \n",
    "        sub_run_df, (break_onsets, break_offsets, break_durations) = add_VTC_get_breaks(sub_run_df, args)\n",
    "\n",
    "        sub_run_desmat = convert_df_to_desMat(\n",
    "                sub_run_df,\n",
    "                sub_trs,\n",
    "                model='VTC_shifted',\n",
    "                VTC_shift = args.VTC_shift,\n",
    "                break_durations=break_durations,\n",
    "            )\n",
    "\n",
    "        # Include a session if a subject experienced all trial types for the contrast\n",
    "        if all(ev in sub_run_desmat.columns for ev in contrast_cols):\n",
    "            curr_timeseries = get_timeseries(timeseries_data[sidx][runidx])\n",
    "            \n",
    "            curr_timeseries, sub_run_desmat, skip_session, bad_trs = check_dataset2_censored_trs(sub_run_desmat, curr_timeseries, args, return_bad_trs=True)\n",
    "            \n",
    "            # GET RESIDUALS FROM EVENT GLM\n",
    "            if not skip_session:\n",
    "                sub_run_events_desmat = convert_df_to_desMat(\n",
    "                    sub_run_df,\n",
    "                    sub_trs,\n",
    "                    model='trialType',\n",
    "                    VTC_shift = args.VTC_shift,\n",
    "                    break_durations=break_durations,\n",
    "                )\n",
    "                if (int(args.dataset)==2) and (args.glm_noise_model=='ar1'):\n",
    "                    # add a junk regressor for every non-border bad TR\n",
    "                    for btr in bad_trs:\n",
    "                        sub_run_events_desmat[f'censor_{btr}'] = 0\n",
    "                        sub_run_events_desmat.loc[btr, f'censor_{btr}'] = 1\n",
    "                    # reset desmat index\n",
    "                    sub_run_events_desmat = sub_run_events_desmat.reset_index(drop=True)\n",
    "                \n",
    "                # fit and get residuals\n",
    "                fitted_flm = fit_edge_flm(\n",
    "                                FirstLevelModel(t_r=args.t_r, signal_scaling=args.signal_scaling, noise_model=args.glm_noise_model, minimize_memory=False),\n",
    "                                run_Ys=[curr_timeseries],\n",
    "                                design_matrices=[sub_run_events_desmat],\n",
    "                            )\n",
    "                curr_timeseries = get_flm_attribute(fitted_flm, 'residuals', result_as_time_series=True)[0]\n",
    "\n",
    "                # shift VTC and drop block breaks\n",
    "                sub_run_desmat, curr_timeseries = exclude_irrelevant_VTC_TRs(sub_run_desmat, curr_timeseries, args, break_onsets, break_offsets)\n",
    "                des_mat_dict[sub].append(sub_run_desmat)    \n",
    "                fitable_timeseries[sub].append(curr_timeseries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd1c3843-b3e6-4467-8bc7-5e4e90b49416",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2_coeff(A, B):\n",
    "    # See https://stackoverflow.com/questions/42677677/python3-computationally-efficient-correlation-between-matrix-and-array\n",
    "    # Rowwise mean of input arrays & subtract from input arrays themeselves\n",
    "    A_mA = A - A.mean(1)[:, None]\n",
    "    B_mB = B - B.mean(1)[:, None]\n",
    "\n",
    "    # Sum of squares across rows\n",
    "    ssA = (A_mA**2).sum(1)\n",
    "    ssB = (B_mB**2).sum(1)\n",
    "\n",
    "    # Finally get corr coeff\n",
    "    return np.dot(A_mA, B_mB.T) / np.sqrt(np.dot(ssA[:, None],ssB[None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc652dc6-6602-4aaf-b874-464c4846cedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df = pd.DataFrame()\n",
    "for sidx, sub in enumerate(des_mat_dict):\n",
    "    n_runs = len(des_mat_dict[sub])\n",
    "    if args.replicate:\n",
    "        sub_zs = np.full((n_runs, args.nROI), np.nan)\n",
    "    else:    \n",
    "        sub_zs = np.full((n_runs, len(ridx)), np.nan)\n",
    "    \n",
    "    for run_idx in range(n_runs):\n",
    "        VTC_ts = des_mat_dict[sub][run_idx].vtc.values\n",
    "        edge_ts = fitable_timeseries[sub][run_idx]\n",
    "        corrs2 = corr2_coeff(edge_ts.T,VTC_ts[:, np.newaxis].T).ravel()\n",
    "        zs = np.arctanh(corrs2)\n",
    "        sub_zs[run_idx, :] = zs\n",
    "    \n",
    "    corr_df = pd.concat([corr_df, \n",
    "              pd.DataFrame(\n",
    "                  np.mean(sub_zs, 0)\n",
    "              ).T\n",
    "              ])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33516caa-3c7c-44d4-8157-b6db766d1388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVE FIRSTLEVEL RESULTS\n",
    "results_str = f'model-VTCcorr_contrast-VTCcorr_datatype-{\"roi\" if args.use_rois else \"edge\"}.csv'\n",
    "corr_df.to_csv(path.join(results_dir, results_str), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
